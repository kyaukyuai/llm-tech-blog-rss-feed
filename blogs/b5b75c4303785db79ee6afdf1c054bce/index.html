<!doctype html><html lang="ja"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="description" content="LLMのテックブログの更新をまとめたRSSフィードを配信しています。記事を読んでその企業の技術・カルチャーを知れることや、質の高い技術情報を得られることを目的としています。"><meta name="author" content="kyaukyuai"><meta name="robots" content="index, follow"><meta property="og:url" content="https://kyaukyuai.github.io/llm-tech-blog-rss-feed/"><meta property="og:title" content="Chip Huyenのフィード｜LLMテックブログRSS"><meta property="og:image" content="https://kyaukyuai.github.io/llm-tech-blog-rss-feed/images/og-image.png"><meta property="og:description" content="LLMのテックブログの更新をまとめたRSSフィードを配信しています。記事を読んでその企業の技術・カルチャーを知れることや、質の高い技術情報を得られることを目的としています。"><meta property="og:type" content="website"><meta property="og:site_name" content="LLMテックブログRSS"><meta property="og:locale" content="ja_JP"><meta name="twitter:card" content="summary"><meta property="twitter:domain" content="https://kyaukyuai.github.io/llm-tech-blog-rss-feed/">
<meta property="twitter:url" content="https://kyaukyuai.github.io/llm-tech-blog-rss-feed/"><meta name="twitter:title" content="Chip Huyenのフィード｜LLMテックブログRSS"><meta name="twitter:description" content="LLMのテックブログの更新をまとめたRSSフィードを配信しています。記事を読んでその企業の技術・カルチャーを知れることや、質の高い技術情報を得られることを目的としています。"><meta name="twitter:image" content="https://kyaukyuai.github.io/llm-tech-blog-rss-feed/images/og-image.png"><meta name="thumbnail" content="https://kyaukyuai.github.io/llm-tech-blog-rss-feed/images/og-image.png"><link rel="preload" href="../../styles/bundle.css" as="style"><link rel="shortcut icon" href="../../images/favicon.ico"><link rel="apple-touch-icon" href="../../images/apple-icon.png"><link rel="alternate" type="application/atom+xml" title="Atom Feed" href="../../feeds/atom.xml"><link rel="alternate" type="application/rss+xml" title="RSS2.0" href="../../feeds/rss.xml"><link rel="alternate" type="application/json" href="../../feeds/feed.json"><link rel="stylesheet" type="text/css" 
href="../../styles/bundle.css"><title>Chip Huyenのフィード｜LLMテックブログRSS</title></head><body><header role="banner" class="ui-section-header"><div class="ui-layout-container"><div class="ui-section-header__layout ui-layout-flex"><a href="https://kyaukyuai.github.io/llm-tech-blog-rss-feed/" role="link" aria-label="#"><img src="../../images/icon.png" alt="サイトロゴ" loading="eager" width="96" height="96"> <span class="ui-section-header__title">LLMテックブログRSS</span> </a><a href="https://github.com/kyaukyuai/llm-tech-blog-rss-feed/" role="link" aria-label="#"><img src="../../images/github-mark.png" alt="GitHubロゴ" loading="eager" width="96" height="96"></a></div></div></header><main role="main"><nav class="ui-nav"><div class="ui-layout-container"><div class="ui-section-nav__layout ui-layout-flex"><a class="ui-section-nav__link" href="../../">フィード</a> <a class="ui-section-nav__link" href="../../hot/">人気フィード</a> <a class="ui-section-nav__link" href="../../blogs/">ブログ一覧</a></div></div></nav><section 
class="ui-section-content ui-section-feed"><div class="ui-layout-container"><h2 class="ui-typography-heading">Chip Huyen</h2><div class="ui-container-blog-summary"><div class="ui-blog-summary"><a class="ui-blog-summary__link" href="https://huyenchip.com">https://huyenchip.com</a><p class="ui-blog-summary__description">I help companies deploy machine learning into production. I write about AI applications, tooling, and best practices.</p></div></div><h3 class="ui-typography-heading">フィード</h3><div class="ui-section-content--feature ui-layout-grid ui-layout-grid-3 ui-container-feed ui-container-feed--no-image"><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://huyenchip.com//2024/04/17/personal-growth.html"><img src="../../images/alternate-feed-image.png" loading="lazy" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://huyenchip.com//2024/04/17/personal-growth.html">
Measuring personal growth</a><div class="ui-feed-item__blog-title">Chip Huyen</div><div class="ui-feed-item__summary">
My founder friends constantly think about growth. They think about how to measure their business growth and how to get to the next order of magnitude scale. If they’re making $1M ARR today, they think about how to get to $10M ARR. If they have 1,000 users today, they think about how to get to 10,000 users.This made me wonder if/how people are measuring personal growth. I don’t want to use metrics like net worth or the number of followers, because that’s not what I live for. After talking with a lot of friends, I found three interesting metrics: rate of change, time to solve problems, and number of future options.Some friends told me they find this blog post mildly sociopathic. Why do I have to measure everything? Life is to be lived, not to be measured. As someone lowkey fascinated by numbers, I don’t see why measuring and living have to be mutually exclusive – measuring often helps me live better – but I see where they come from. This post is more of a thought exercise than a rigorous
</div><div class="ui-feed-item__date" title="2024-04-17 00:00:00">3ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://huyenchip.com//2024/03/14/ai-oss.html"><img src="../../images/alternate-feed-image.png" loading="lazy" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://huyenchip.com//2024/03/14/ai-oss.html">What I learned from looking at 900 most popular open source AI tools</a><div class="ui-feed-item__blog-title">Chip Huyen</div><div class="ui-feed-item__summary">
[Hacker News discussion, LinkedIn discussion, Twitter thread]Four years ago, I did an analysis of the open source ML ecosystem. Since then, the landscape has changed, so I revisited the topic. This time, I focused exclusively on the stack around foundation models.The full list of open source AI repos is hosted at llama-police. The list is updated every 6 hours. You can also find most of them on my cool-llm-repos list on GitHub.Table of contentsDataHow to add missing reposThe New AI StackAI stack over timeApplicationsAI engineeringModel developmentInfrastructureOpen source AI developersOne-person billion-dollar companies?1 million commitsThe growing China’s open source ecosystemLive fast, die youngMy personal favorite ideasConclusionDataI searched GitHub using the keywords gpt, llm, and generative ai. If AI feels so overwhelming right now, it’s because it is. There are 118K results for gpt alone.To make my life easier, I limited my search to the repos with at least 500 stars. There were
</div><div class="ui-feed-item__date" title="2024-03-14 00:00:00">4ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://huyenchip.com//2024/02/28/predictive-human-preference.html"><img src="../../images/alternate-feed-image.png" loading="lazy" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://huyenchip.com//2024/02/28/predictive-human-preference.html">Predictive Human Preference: From Model Ranking to Model Routing</a><div class="ui-feed-item__blog-title">Chip Huyen</div><div class="ui-feed-item__summary">
A challenge of building AI applications is choosing which model to use. What if we don’t have to? What if we can predict the best model for any prompt? Predictive human preference aims to predict which model users might prefer for a specific query.Table of contentsRanking Models Using Human PreferenceHow Preferential Ranking WorksCorrectness of Chatbot Arena RankingEval dataResultsPredicting Human Preference For Each PromptExperiment setupExperiment resultsDomain-specific and query-specific leaderboardsConclusionHuman preference has emerged to be both the Northstar and a powerful tool for AI model development. Human preference guides post-training techniques including RLHF and DPO. Human preference is also used to rank AI models, as used by LMSYS’s Chatbot Arena.Chatbot Arena aims to determine which model is generally preferred. I wanted to see if it’s possible to predict which model is preferred for each query.One use case of predictive human preference is model routing. For example,
</div><div class="ui-feed-item__date" title="2024-02-28 00:00:00">4ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://huyenchip.com//2024/01/16/sampling.html"><img src="../../images/alternate-feed-image.png" loading="lazy" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://huyenchip.com//2024/01/16/sampling.html">Sampling for Text Generation</a><div class="ui-feed-item__blog-title">Chip Huyen</div><div class="ui-feed-item__summary">
ML models are probabilistic. Imagine that you want to know what’s the best cuisine in the world. If you ask someone this question twice, a minute apart, their answers both times should be the same. If you ask a model the same question twice, its answer can change. If the model thinks that Vietnamese cuisine has a 70% chance of being the best cuisine and Italian cuisine has a 30% chance, it’ll answer “Vietnamese” 70% of the time, and “Italian” 30%.This probabilistic nature makes AI great for creative tasks. What is creativity but the ability to explore beyond the common possibilities, to think outside the box?However, this probabilistic nature also causes inconsistency and hallucinations. It’s fatal for tasks that depend on factuality. Recently, I went over 3 months’ worth of customer support requests of an AI startup I advise and found that ⅕ of the questions are because users don’t understand or don’t know how to work with this probabilistic nature.To understand why AI’s responses are
</div><div class="ui-feed-item__date" title="2024-01-16 00:00:00">6ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://huyenchip.com//2023/10/10/multimodal.html"><img src="../../images/alternate-feed-image.png" loading="lazy" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://huyenchip.com//2023/10/10/multimodal.html">Multimodality and Large Multimodal Models (LMMs)</a><div class="ui-feed-item__blog-title">Chip Huyen</div><div class="ui-feed-item__summary">
For a long time, each ML model operated in one data mode – text (translation, language modeling), image (object detection, image classification), or audio (speech recognition).However, natural intelligence is not limited to just a single modality. Humans can read, talk, and see. We listen to music to relax and watch out for strange noises to detect danger. Being able to work with multimodal data is essential for us or any AI to operate in the real world.OpenAI noted in their GPT-4V system card that “incorporating additional modalities (such as image inputs) into LLMs is viewed by some as a key frontier in AI research and development.”Incorporating additional modalities to LLMs (Large Language Models) creates LMMs (Large Multimodal Models). Not all multimodal systems are LMMs. For example, text-to-image models like Midjourney, Stable Diffusion, and Dall-E are multimodal but don’t have a language model component. Multimodal can mean one or more of the following:Input and output are of di
</div><div class="ui-feed-item__date" title="2023-10-10 00:00:00">9ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://huyenchip.com//2023/08/16/llm-research-open-challenges.html"><img src="../../images/alternate-feed-image.png" loading="lazy" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://huyenchip.com//2023/08/16/llm-research-open-challenges.html">Open challenges in LLM research</a><div class="ui-feed-item__blog-title">Chip Huyen</div><div class="ui-feed-item__summary">
[LinkedIn discussion, Twitter thread]Never before in my life had I seen so many smart people working on the same goal: making LLMs better. After talking to many people working in both industry and academia, I noticed the 10 major research directions that emerged. The first two directions, hallucinations and context learning, are probably the most talked about today. I’m the most excited about numbers 3 (multimodality), 5 (new architecture), and 6 (GPU alternatives).Open challenges in LLM research1. Reduce and measure hallucinations2. Optimize context length and context construction3. Incorporate other data modalities4. Make LLMs faster and cheaper5. Design a new model architecture6. Develop GPU alternatives7. Make agents usable8. Improve learning from human preference9. Improve the efficiency of the chat interface10. Build LLMs for non-English languages1. Reduce and measure hallucinationsHallucination is a heavily discussed topic already so I’ll be quick. Hallucination happens when an
</div><div class="ui-feed-item__date" title="2023-08-16 00:00:00">1年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://huyenchip.com//2023/06/07/generative-ai-strategy.html"><img src="../../images/alternate-feed-image.png" loading="lazy" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://huyenchip.com//2023/06/07/generative-ai-strategy.html">Generative AI Strategy</a><div class="ui-feed-item__blog-title">Chip Huyen</div><div class="ui-feed-item__summary">
I had a lot of fun preparing the talk: “Leadership needs us to do generative AI. What do we do?” for Fully Connected. The idea for the talk came from many conversations I’ve had recently with friends who need to figure out their generative AI strategy, but aren’t sure what exactly to do.This talk is a simple framework to explore what to do with generative AI. Many ideas are still being fleshed out. I hope to convert this into a proper post when I have more time. In the meantime, I’d love to hear from your experience through this process.I couldn’t figure out how to make the slides centered on the page. You might want to download the slides.Thanks everyone who responded to my post and shared your thoughts on what I should include in the talk. Thanks Kyle Gallatin, Goku Mohandas, Han-chung Lee, and Jamie de Guerre for thoughtful feedback on the talk.</div><div class="ui-feed-item__date" title="2023-06-07 00:00:00">1年前</div></div></div><div class="ui-feed-item"><a 
class="ui-feed-item__og-image" href="https://huyenchip.com//2023/05/02/rlhf.html"><img src="../../images/alternate-feed-image.png" loading="lazy" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://huyenchip.com//2023/05/02/rlhf.html">RLHF: Reinforcement Learning from Human Feedback</a><div class="ui-feed-item__blog-title">Chip Huyen</div><div class="ui-feed-item__summary">
[LinkedIn discussion, Twitter thread]In literature discussing why ChatGPT is able to capture so much of our imagination, I often come across two narratives:Scale: throwing more data and compute at it.UX: moving from a prompt interface to a more natural chat interface.One narrative that is often glossed over is the incredible technical creativity that went into making models like ChatGPT work. One such cool idea is RLHF (Reinforcement Learning from Human Feedback): incorporating reinforcement learning and human feedback into NLP.RL has been notoriously difficult to work with, and therefore, mostly confined to gaming and simulated environments like Atari or MuJoCo. Just five years ago, both RL and NLP were progressing pretty much orthogonally – different stacks, different techniques, and different experimentation setups. It’s impressive to see it work in a new domain at a massive scale.So, how exactly does RLHF work? Why does it work? This post will discuss the answers to those questions
</div><div class="ui-feed-item__date" title="2023-05-02 00:00:00">1年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://huyenchip.com//2023/04/11/llm-engineering.html"><img src="../../images/alternate-feed-image.png" loading="lazy" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://huyenchip.com//2023/04/11/llm-engineering.html">Building LLM applications for production</a><div class="ui-feed-item__blog-title">Chip Huyen</div><div class="ui-feed-item__summary">
[Hacker News discussion, LinkedIn discussion, Twitter thread]A question that I’ve been asked a lot recently is how large language models (LLMs) will change machine learning workflows. After working with several companies who are working with LLM applications and personally going down a rabbit hole building my applications, I realized two things:It’s easy to make something cool with LLMs, but very hard to make something production-ready with them.LLM limitations are exacerbated by a lack of engineering rigor in prompt engineering, partially due to the ambiguous nature of natural languages, and partially due to the nascent nature of the field.This post consists of three parts.Part 1 discusses the key challenges of productionizing LLM applications and the solutions that I’ve seen.Part 2 discusses how to compose multiple tasks with control flows (e.g. if statement, for loop) and incorporate tools (e.g. SQL executor, bash, web browsers, third-party APIs) for more complex and powerful applic
</div><div class="ui-feed-item__date" title="2023-04-11 00:00:00">1年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://huyenchip.com//2023/01/24/what-we-look-for-in-a-candidate.html"><img src="../../images/alternate-feed-image.png" loading="lazy" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://huyenchip.com//2023/01/24/what-we-look-for-in-a-candidate.html">What we look for in a resume</a><div class="ui-feed-item__blog-title">Chip Huyen</div><div class="ui-feed-item__summary">
I read every single one of the resumes we receive. Sometimes, I’d talk to a candidate and see that what we perceived as their strongest aspects actually weren’t included in their resume. Occasionally, a candidate would tell me that they didn’t expect their resume to still be screened by humans – had they known, they would have written their resume differently.The resume evaluation process is pretty much a black box for most candidates. And it is so because few hiring managers have publicly discussed this. I thought I should start the conversation.“Resume” here refers to both the traditional resumes and LinkedIn profiles. If your LinkedIn is current and contains all the information you want to share, that’s perfectly fine. Some hiring managers I know at other companies actually prefer looking at LinkedIn because they find it faster to find the info they need (e.g. company logos, time spent at each company). I’ve also seen candidates who use their personal websites as their resumes, whic
</div><div class="ui-feed-item__date" title="2023-01-24 00:00:00">1年前</div></div></div></div></div></section></main><footer role="contentinfo" class="ui-section-footer"><div class="ui-layout-container"><div class="ui-layout-column-6 ui-layout-column-center"><div class="ui-component-cta ui-layout-flex ui-section-footer__site-info"><p class="ui-text-note">このサイトは<br>記事を読んでその企業の技術・カルチャーを知れることや<br>質の高い技術情報を得られることを目的としています。</p><p class="ui-text-note">追加したいブログがある場合は<br><a href="https://github.com/kyaukyuai/llm-tech-blog-rss-feed#%E3%82%B5%E3%82%A4%E3%83%88%E3%81%AE%E8%BF%BD%E5%8A%A0%E6%96%B9%E6%B3%95">サイトの追加方法</a> をご参照ください。</p></div></div></div><div class="ui-layout-container"><div class="ui-section-footer__layout ui-layout-flex"><p class="ui-section-footer--copyright ui-text-note"><a class="ui-text-note" href="https://github.com/kyaukyuai/"><small>@kyaukyuai</small></a></p><a href="https://github.com/kyaukyuai/llm-tech-blog-rss-feed/" role="link" aria-label="#" class="ui-text-note"><small>
GitHub</small></a></div></div></footer></body></html>